{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ANOTATION\n",
    "Este codigo te pone a anotar esquinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (102513208 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (99534279 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (100316160 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (99322949 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (99038940 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (106610944 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (106315008 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (105928832 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (100703840 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (104593280 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (102983680 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (114442560 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DanielHP\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3218: DecompressionBombWarning: Image size (102236112 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay más imágenes.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk, ImageDraw\n",
    "import os\n",
    "\n",
    "# Configuración inicial\n",
    "input_folder = r\"data\\ok\"\n",
    "output_folder = os.path.join(input_folder, \"annotations\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Variables globales\n",
    "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "current_index = 0\n",
    "rect_start = None\n",
    "rect_end = None\n",
    "rect_id = None\n",
    "zoom_level = 1.0\n",
    "current_image = None\n",
    "img_tk = None\n",
    "offset_x = 0\n",
    "offset_y = 0\n",
    "pan_start = None\n",
    "\n",
    "# Funciones principales\n",
    "def load_image(index):\n",
    "    if 0 <= index < len(image_files):\n",
    "        image_path = os.path.join(input_folder, image_files[index])\n",
    "        image = Image.open(image_path)\n",
    "        return image\n",
    "    return None\n",
    "\n",
    "def save_rectangle(image, start, end, output_path):\n",
    "    cropped = image.crop((min(start[0], end[0]), min(start[1], end[1]),\n",
    "                          max(start[0], end[0]), max(start[1], end[1])))\n",
    "    cropped.save(output_path)\n",
    "\n",
    "def on_mouse_press(event):\n",
    "    global rect_start, rect_id, pan_start\n",
    "    if event.num == 1:  # Left click\n",
    "        rect_start = (int((event.x - offset_x) / zoom_level), int((event.y - offset_y) / zoom_level))\n",
    "        rect_id = canvas.create_rectangle(event.x, event.y, event.x, event.y, outline=\"red\")\n",
    "    elif event.num == 3:  # Right click\n",
    "        pan_start = (event.x, event.y)\n",
    "\n",
    "def on_mouse_drag(event):\n",
    "    global rect_id, offset_x, offset_y, pan_start\n",
    "    if rect_id and rect_start:\n",
    "        canvas.coords(rect_id, rect_start[0] * zoom_level + offset_x, rect_start[1] * zoom_level + offset_y, event.x, event.y)\n",
    "    elif pan_start:\n",
    "        dx = event.x - pan_start[0]\n",
    "        dy = event.y - pan_start[1]\n",
    "        offset_x += dx\n",
    "        offset_y += dy\n",
    "        pan_start = (event.x, event.y)\n",
    "        update_canvas()\n",
    "\n",
    "def on_mouse_release(event):\n",
    "    global rect_start, rect_end, rect_id, current_image, pan_start\n",
    "    if event.num == 1 and rect_start:  # Left click release\n",
    "        rect_end = (int((event.x - offset_x) / zoom_level), int((event.y - offset_y) / zoom_level))\n",
    "        if rect_start and rect_end:\n",
    "            output_path = os.path.join(output_folder, f\"annotation_{current_index}_{rect_start[0]}_{rect_start[1]}_{rect_end[0]}_{rect_end[1]}.png\")\n",
    "            save_rectangle(current_image, rect_start, rect_end, output_path)\n",
    "        rect_start = None\n",
    "        rect_end = None\n",
    "        rect_id = None\n",
    "    elif event.num == 3:  # Right click release\n",
    "        pan_start = None\n",
    "\n",
    "import time\n",
    "\n",
    "last_zoom_time = 0  # Variable global para limitar la frecuencia de zoom\n",
    "ZOOM_MIN = 0.1      # Zoom mínimo\n",
    "ZOOM_MAX = 10.0     # Zoom máximo\n",
    "\n",
    "def on_mouse_wheel(event):\n",
    "    global zoom_level, offset_x, offset_y, last_zoom_time\n",
    "    \n",
    "    # Limitar frecuencia de zoom\n",
    "    current_time = time.time()\n",
    "    if current_time - last_zoom_time < 0.05:  # 50 ms entre eventos\n",
    "        return\n",
    "    last_zoom_time = current_time\n",
    "\n",
    "    # Calcular factor de zoom\n",
    "    factor = 1.1 if event.delta > 0 else 0.9\n",
    "    new_zoom_level = zoom_level * factor\n",
    "\n",
    "    # Restringir niveles de zoom\n",
    "    if not (ZOOM_MIN <= new_zoom_level <= ZOOM_MAX):\n",
    "        return\n",
    "\n",
    "    # Ajustar desplazamiento para centrarse en el cursor\n",
    "    cursor_x = canvas.canvasx(event.x)\n",
    "    cursor_y = canvas.canvasy(event.y)\n",
    "    offset_x = cursor_x - factor * (cursor_x - offset_x)\n",
    "    offset_y = cursor_y - factor * (cursor_y - offset_y)\n",
    "\n",
    "    # Actualizar nivel de zoom y redibujar\n",
    "    zoom_level = new_zoom_level\n",
    "    update_canvas()\n",
    "\n",
    "\n",
    "def next_image():\n",
    "    global current_index, current_image, img_tk, zoom_level, offset_x, offset_y\n",
    "    current_index += 1\n",
    "    zoom_level = 1.0\n",
    "    offset_x = 0\n",
    "    offset_y = 0\n",
    "    if current_index < len(image_files):\n",
    "        current_image = load_image(current_index)\n",
    "        update_canvas()\n",
    "    else:\n",
    "        print(\"No hay más imágenes.\")\n",
    "\n",
    "# def update_canvas():\n",
    "#     global img_tk\n",
    "#     if current_image:\n",
    "#         resized_image = current_image.resize((int(current_image.width * zoom_level), int(current_image.height * zoom_level)))\n",
    "#         img_tk = ImageTk.PhotoImage(resized_image)\n",
    "#         canvas.delete(\"all\")\n",
    "#         canvas.config(scrollregion=(0, 0, resized_image.width + offset_x, resized_image.height + offset_y))\n",
    "#         canvas.create_image(offset_x, offset_y, anchor=tk.NW, image=img_tk)\n",
    "\n",
    "def update_canvas():\n",
    "    global img_tk\n",
    "    if current_image:\n",
    "        # Calcular dimensiones escaladas una vez\n",
    "        scaled_width = int(current_image.width * zoom_level)\n",
    "        scaled_height = int(current_image.height * zoom_level)\n",
    "\n",
    "        # Redimensionar solo si el tamaño cambió\n",
    "        resized_image = current_image.resize((scaled_width, scaled_height))\n",
    "        img_tk = ImageTk.PhotoImage(resized_image)\n",
    "\n",
    "        # Redibujar la imagen (manteniendo el scroll)\n",
    "        canvas.delete(\"image\")  # Borra solo el identificador de la imagen\n",
    "        canvas.create_image(offset_x, offset_y, anchor=tk.NW, image=img_tk, tags=\"image\")\n",
    "\n",
    "        # Actualizar región de scroll\n",
    "        canvas.config(scrollregion=(0, 0, scaled_width, scaled_height))\n",
    "\n",
    "\n",
    "# Crear la interfaz gráfica\n",
    "root = tk.Tk()\n",
    "root.title(\"Herramienta de Anotación Rápida\")\n",
    "\n",
    "canvas = tk.Canvas(root)\n",
    "canvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "frame_buttons = tk.Frame(root)\n",
    "frame_buttons.pack()\n",
    "\n",
    "btn_next = tk.Button(frame_buttons, text=\"Siguiente Imagen\", command=next_image)\n",
    "btn_next.pack(side=tk.LEFT)\n",
    "\n",
    "canvas.bind(\"<ButtonPress-1>\", on_mouse_press)\n",
    "canvas.bind(\"<B1-Motion>\", on_mouse_drag)\n",
    "canvas.bind(\"<ButtonRelease-1>\", on_mouse_release)\n",
    "canvas.bind(\"<MouseWheel>\", on_mouse_wheel)\n",
    "canvas.bind(\"<ButtonPress-3>\", on_mouse_press)\n",
    "canvas.bind(\"<B3-Motion>\", on_mouse_drag)\n",
    "canvas.bind(\"<ButtonRelease-3>\", on_mouse_release)\n",
    "\n",
    "# Cargar la primera imagen\n",
    "if image_files:\n",
    "    current_image = load_image(current_index)\n",
    "    update_canvas()\n",
    "else:\n",
    "    print(\"No se encontraron imágenes en la carpeta especificada.\")\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random sampler\n",
    "Este otro codigo coge pedacitos random de las imagenes para crear los negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Configuración inicial\n",
    "input_folder = r\"E:\\Universidad\\ML\\ML-Project\\data\\Generales-Parciales\"\n",
    "output_folder = os.path.join(input_folder, \"random_crops\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Número total de subimágenes y tamaño del recorte\n",
    "num_total_crops = 5600\n",
    "crop_size = 200\n",
    "\n",
    "# Obtener la lista de imágenes\n",
    "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "num_images = len(image_files)\n",
    "if num_images == 0:\n",
    "    raise ValueError(\"No se encontraron imágenes en la carpeta especificada.\")\n",
    "\n",
    "# Cantidad de recortes por imagen\n",
    "crops_per_image = num_total_crops // num_images\n",
    "\n",
    "# Generar recortes aleatorios\n",
    "def generate_random_crops(image_path, num_crops, crop_size, output_folder):\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        for i in range(num_crops):\n",
    "            if width < crop_size or height < crop_size:\n",
    "                raise ValueError(f\"La imagen {image_path} es más pequeña que el tamaño del recorte ({crop_size}x{crop_size}).\")\n",
    "\n",
    "            left = random.randint(0, width - crop_size)\n",
    "            top = random.randint(0, height - crop_size)\n",
    "            right = left + crop_size\n",
    "            bottom = top + crop_size\n",
    "\n",
    "            crop = img.crop((left, top, right, bottom))\n",
    "            crop_filename = f\"{os.path.splitext(os.path.basename(image_path))[0]}_crop_{i}.png\"\n",
    "            crop.save(os.path.join(output_folder, crop_filename))\n",
    "\n",
    "# Procesar cada imagen\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    generate_random_crops(image_path, crops_per_image, crop_size, output_folder)\n",
    "\n",
    "print(f\"Se generaron {num_total_crops} recortes aleatorios de {crop_size}x{crop_size} y se guardaron en la carpeta {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt  # <-- Importar matplotlib\n",
    "\n",
    "class BorderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.rotation_angles = [90, 180, 270]  # Ángulos para rotaciones adicionales\n",
    "        \n",
    "        borders_dir = os.path.join(root_dir, \"borders\")\n",
    "        for img_name in os.listdir(borders_dir):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "                img_path = os.path.join(borders_dir, img_name)\n",
    "                # Imagen original\n",
    "                self.samples.append((img_path, 0))\n",
    "                # Agregar rotaciones\n",
    "                for angle in self.rotation_angles:\n",
    "                    self.samples.append((img_path, 0, angle))\n",
    "        \n",
    "        no_borders_dir = os.path.join(root_dir, \"no_borders\")\n",
    "        for img_name in os.listdir(no_borders_dir):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "                img_path = os.path.join(no_borders_dir, img_name)\n",
    "                self.samples.append((img_path, 1))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.samples[idx]) == 2:\n",
    "            # Imagen sin rotación\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        else:\n",
    "            # Imagen con rotación\n",
    "            img_path, label, angle = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = image.rotate(angle)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def check_data_directory(data_dir):\n",
    "    \"\"\"Verifica que existan las carpetas necesarias con las imágenes\"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"El directorio {data_dir} no existe\")\n",
    "    \n",
    "    borders_dir = os.path.join(data_dir, \"borders\")\n",
    "    no_borders_dir = os.path.join(data_dir, \"no_borders\")\n",
    "    \n",
    "    if not os.path.exists(borders_dir):\n",
    "        raise FileNotFoundError(f\"No se encuentra la carpeta 'borders' en {data_dir}\")\n",
    "    if not os.path.exists(no_borders_dir):\n",
    "        raise FileNotFoundError(f\"No se encuentra la carpeta 'no_borders' en {data_dir}\")\n",
    "    \n",
    "    # Verificar que hay imágenes en las carpetas\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "    borders_images = [f for f in os.listdir(borders_dir) if f.lower().endswith(valid_extensions)]\n",
    "    no_borders_images = [f for f in os.listdir(no_borders_dir) if f.lower().endswith(valid_extensions)]\n",
    "    \n",
    "    if not borders_images:\n",
    "        raise FileNotFoundError(f\"No se encontraron imágenes válidas en {borders_dir}\")\n",
    "    if not no_borders_images:\n",
    "        raise FileNotFoundError(f\"No se encontraron imágenes válidas en {no_borders_dir}\")\n",
    "    \n",
    "    print(f\"Encontradas {len(borders_images)} imágenes con bordes\")\n",
    "    print(f\"Después del data augmentation: {len(borders_images) * 4} imágenes con bordes\")\n",
    "    print(f\"Encontradas {len(no_borders_images)} imágenes sin bordes\")\n",
    "\n",
    "def main():\n",
    "    # ==============================================================================\n",
    "    # CONFIGURACIÓN BÁSICA\n",
    "    # ==============================================================================\n",
    "    DATA_DIR = os.path.abspath(\"dataset\")\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 1e-3\n",
    "    \n",
    "    # Verificar la estructura del directorio y las imágenes\n",
    "    try:\n",
    "        check_data_directory(DATA_DIR)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error al cargar los datos: {str(e)}\")\n",
    "        print(\"\\nAsegúrate de que tu estructura de directorios sea así:\")\n",
    "        print(\"dataset/\")\n",
    "        print(\"├── borders/\")\n",
    "        print(\"│   ├── imagen1.jpg\")\n",
    "        print(\"│   └── ...\")\n",
    "        print(\"└── no_borders/\")\n",
    "        print(\"    ├── imagen1.jpg\")\n",
    "        print(\"    └── ...\")\n",
    "        return\n",
    "\n",
    "    # Dispositivo: GPU si está disponible, sino CPU\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "    # ==============================================================================\n",
    "    # TRANSFORMS Y DATASET\n",
    "    # ==============================================================================\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Usar nuestro dataset personalizado\n",
    "    full_dataset = BorderDataset(DATA_DIR, transform=data_transforms)\n",
    "    \n",
    "    # Separar en train y valid (80% - 20%)\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    # Ajustar num_workers a 0 para evitar bloqueos (sobre todo en Windows)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Total de imágenes (incluyendo augmentation): {total_size}\")\n",
    "    print(f\"Imágenes de entrenamiento: {train_size}\")\n",
    "    print(f\"Imágenes de validación: {val_size}\")\n",
    "\n",
    "    # ==============================================================================\n",
    "    # DEFINICIÓN DE LA RED NEURONAL CONVOLUCIONAL\n",
    "    # ==============================================================================\n",
    "    class BorderDetectionCNN(nn.Module):\n",
    "        def __init__(self, num_classes=2):\n",
    "            super(BorderDetectionCNN, self).__init__()\n",
    "            \n",
    "            # Capas convolucionales\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "            self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "            \n",
    "            # BatchNorm\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            self.bn3 = nn.BatchNorm2d(128)\n",
    "            self.bn4 = nn.BatchNorm2d(256)\n",
    "            \n",
    "            # Dropout para regularización\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            \n",
    "            # MaxPool 2x2\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            # Clasificador final\n",
    "            # 224 -> 112 -> 56 -> 28 -> 14 (reducción cada pool)\n",
    "            self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "            self.fc2 = nn.Linear(512, num_classes)\n",
    "            \n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = self.conv4(x)\n",
    "            x = self.bn4(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    # Instanciar el modelo y moverlo a GPU/CPU\n",
    "    model = BorderDetectionCNN(num_classes=2).to(DEVICE)\n",
    "\n",
    "    # Definir función de pérdida y optimizador\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Scheduler para ajuste dinámico del LR (opcional)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "    # ==============================================================================\n",
    "    # ENTRENAMIENTO\n",
    "    # ==============================================================================\n",
    "\n",
    "    # -- Inicializar listas para graficar\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    \n",
    "    # -- Configuración de matplotlib en modo interactivo\n",
    "    plt.ion()  \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    def train_one_epoch(epoch):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f'  Época [{epoch+1}/{EPOCHS}], Batch [{i+1}/{len(train_loader)}], '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100.0 * correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def validate_one_epoch():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = running_loss / len(val_loader)\n",
    "        val_acc = 100.0 * correct / total\n",
    "        return val_loss, val_acc\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"==> Época {epoch+1}/{EPOCHS} <==\")\n",
    "        train_loss, train_acc = train_one_epoch(epoch)\n",
    "        val_loss, val_acc = validate_one_epoch()\n",
    "        \n",
    "        # Guardar resultados\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Actualizar learning rate con el scheduler (si se usa)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Guardar el mejor modelo (según val_loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"mejor_modelo_bordes.pth\")\n",
    "\n",
    "        # Mostrar métricas de la época\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        #       Actualización de las gráficas (cada época)\n",
    "        # -------------------------------------------------------------\n",
    "        ax1.clear()\n",
    "        ax1.plot(range(1, epoch+2), train_losses, label='Train Loss')\n",
    "        ax1.plot(range(1, epoch+2), val_losses, label='Val Loss')\n",
    "        ax1.set_title('Loss durante el entrenamiento')\n",
    "        ax1.set_xlabel('Época')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2.clear()\n",
    "        ax2.plot(range(1, epoch+2), train_accuracies, label='Train Acc')\n",
    "        ax2.plot(range(1, epoch+2), val_accuracies, label='Val Acc')\n",
    "        ax2.set_title('Accuracy durante el entrenamiento')\n",
    "        ax2.set_xlabel('Época')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.01)  # Pausa pequeña para actualizar la gráfica\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Entrenamiento finalizado en {total_time:.2f} segundos.\")\n",
    "    print(f\"Mejor modelo guardado como 'mejor_modelo_bordes.pth'\")\n",
    "\n",
    "    # Detenemos el modo interactivo para que la ventana no se cierre inmediatamente\n",
    "    plt.ioff()\n",
    "    # Mantener la gráfica al finalizar\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap\n",
    "\n",
    "Para cambiar el tamannio de los cuadraditos cambia:\n",
    "> WINDOW_SIZE = height // 75\n",
    "\n",
    "Ademas ten en cuenta que yo estoy haciendole el heatmap a una imagen en la misma carpeta llamada habana2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definir el modelo previamente entrenado\n",
    "class BorderDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(BorderDetectionCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model_path = \"mejor_modelo_bordes.pth\"\n",
    "model = BorderDetectionCNN(num_classes=2)\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Leer la imagen\n",
    "image_path = \"habana2.jpg\"\n",
    "original_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Convertir a escala de grises\n",
    "img_array = np.array(original_image.convert(\"L\"))\n",
    "\n",
    "height, width = img_array.shape\n",
    "WINDOW_SIZE = height // 75\n",
    "if WINDOW_SIZE < 2:\n",
    "    WINDOW_SIZE = 2\n",
    "\n",
    "STEP_SIZE = WINDOW_SIZE // 2\n",
    "if STEP_SIZE < 1:\n",
    "    STEP_SIZE = 1\n",
    "\n",
    "print(f\"WINDOW_SIZE = {WINDOW_SIZE}, STEP_SIZE = {STEP_SIZE}\")\n",
    "\n",
    "# Crear heatmap y mapa de conteo\n",
    "heatmap = np.zeros((height, width), dtype=np.float32)\n",
    "count_map = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "# Transformación para el modelo\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Pasar por cada ventana deslizante\n",
    "for y in range(0, height - WINDOW_SIZE, STEP_SIZE):\n",
    "    for x in range(0, width - WINDOW_SIZE, STEP_SIZE):\n",
    "        patch = img_array[y : y + WINDOW_SIZE, x : x + WINDOW_SIZE]\n",
    "        \n",
    "        # Convertir a 3 canales\n",
    "        patch_3ch = np.stack([patch, patch, patch], axis=2)\n",
    "        \n",
    "        # Transformar y pasar por el modelo\n",
    "        patch_tensor = transform(patch_3ch).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(patch_tensor)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Probabilidad de borde (clase 0)\n",
    "        prob_border = 1-probs[0, 0].item()\n",
    "\n",
    "        heatmap[y : y + WINDOW_SIZE, x : x + WINDOW_SIZE] += prob_border\n",
    "        count_map[y : y + WINDOW_SIZE, x : x + WINDOW_SIZE] += 1\n",
    "\n",
    "# Normalizar heatmap\n",
    "count_map = np.maximum(count_map, 1e-5)\n",
    "heatmap /= count_map\n",
    "heatmap_normalized = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "\n",
    "# Crear mapa de colores y superposición\n",
    "base_img_color = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)\n",
    "cmap = cm.get_cmap('jet')\n",
    "heatmap_color = cmap(heatmap_normalized)[..., :3]  # Eliminar canal alpha\n",
    "heatmap_color = (heatmap_color * 255).astype(np.uint8)\n",
    "\n",
    "# Superponer el heatmap con la imagen base\n",
    "alpha = 0.5\n",
    "overlay = cv2.addWeighted(base_img_color, 1.0 - alpha, heatmap_color, alpha, 0)\n",
    "\n",
    "# Guardar resultado\n",
    "output_path = \"heatmap_output.png\"\n",
    "cv2.imwrite(output_path, overlay)\n",
    "print(\"Heatmap guardado en:\", output_path)\n",
    "\n",
    "# Mostrar resultado\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(overlay[..., ::-1])  # Cambiar BGR a RGB para matplotlib\n",
    "plt.title(\"Heatmap de Bordes\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
